## **To Do**

**Level 1 (Product Manager Study):**
- **Video:**
- **Blog:**

**Level 2 (Junior Data Scientist):**
- **Code:**
  - [day19.ipynb](notebooks/day19.ipynb)
- **Books:**
- **Interview questions:**
  - [Easy Interview Questions](interview_questions/easy_questions.md)

**Level 3 (Data Scientist):**
- **Interview questions:**
  - [Medium Interview Questions](interview_questions/medium_questions.md)
- **Books:**

## **Plan**

**Objectives:**
- Study the historical LeNet-5 architecture
- Understand early CNN design principles
- Implement LeNet-5 from scratch
- Learn about architectural evolution
- Understand the impact of LeNet-5 on computer vision

**Deep Learning Concept(s):**
- LeNet-5 architecture (1998)
- Historical significance: first successful CNN
- Architecture: 2 conv layers + 3 FC layers
- Handwritten digit recognition
- Tanh activations (historical, now use ReLU)
- Subsampling layers (historical pooling)

**Tools Used:**
- PyTorch: implementing LeNet-5 architecture
- Functions: Building LeNet-5 with specific layer configurations

**Key Learnings:**
- LeNet-5 architecture details: Conv(6) → Pool → Conv(16) → Pool → FC(120) → FC(84) → FC(10)
- Understanding historical vs. modern CNN design
- Appreciating architectural evolution
- Implementing specific architectures from papers
- Understanding that modern CNNs build on these foundations
- Learning to read and implement architectures from research papers

**References:**
- **Paper**: LeCun, Y., et al. (1998). "Gradient-based learning applied to document recognition"
- **Book**: "Deep Learning" by Ian Goodfellow - Chapter 9.9 (Convolutional Networks - Historical Context)
- **Online**: [LeNet-5 Architecture Explained](https://medium.com/@mayurmalviya/lenet-5-a-classic-cnn-architecture-2735f58c8915)
- **Tutorial**: [Implementing LeNet-5 in PyTorch](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html)

---