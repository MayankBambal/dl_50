# Course Syllabus

Complete syllabus for the 50 Days of Deep Learning course.

## Course Overview

This course is designed to take you from absolute beginner to proficient in deep learning, covering fundamental concepts through advanced architectures like Transformers, BERT, and GPT.

**Duration:** 50 days  
**Format:** Self-paced  
**Prerequisites:** Basic Python programming  
**Completion Deadline:** December 31st, 2025  
**Goal:** Finish your 2025 resolution

**Framework:** This course focuses exclusively on PyTorch to maximize learning efficiency in this intensive 50-day format. We use Python as our sole programming language to keep the course focused and streamlined.

**Environment:** This course is designed to be used with **Google Colab** throughout. All notebooks are optimized for Google Colab, which provides free GPU access and pre-installed libraries, making it the ideal environment for learning deep learning without local setup hassles.

## ðŸŽ¯ The Commitment

**The course will finish on December 31st, 2025. Let's finish this year's resolutionâ€”together.**

This year, let's actually complete what we started. No more abandoned courses. Just 1-2 hours daily, starting today, finishing by December 31st, 2025.

## Learning Outcomes

Upon completion, students will be able to:

1. Understand the mathematical foundations of neural networks
2. Build and train deep learning models from scratch
3. Implement CNNs for computer vision tasks
4. Work with RNNs and LSTMs for sequence data
5. Understand and implement attention mechanisms
6. Build transformer architectures
7. Fine-tune pre-trained models (BERT, GPT)
8. Deploy models for production use

## Course Structure

### Week 1: The Absolute Basics (Days 1-7)

**Theme:** Foundation concepts

**Topics:**
- Day 1: Introduction to Deep Learning
- Day 2: The Perceptron
- Day 3: Multi-Layer Perceptrons
- Day 4: Backpropagation
- Day 5: Activation Functions
- Day 6: Loss Functions
- Day 7: Optimizers

**Projects:** Basic neural network implementation

### Week 2: Building Your First Practical Model (Days 8-14)

**Theme:** Practical training and regularization

**Topics:**
- Day 8: First "Hello World" (MNIST)
- Day 9: Overfitting
- Day 10: Regularization (L1, L2)
- Day 11: Dropout
- Day 12: Hyperparameter Tuning
- Day 13: Batch Normalization
- Day 14: Advanced Optimizers (Adam)

**Projects:** Image classification on MNIST

### Week 3: Deep Learning for Images (Days 15-21)

**Theme:** Convolutional Neural Networks

**Topics:**
- Day 15: Why MLPs fail for images
- Day 16: Convolution Layers
- Day 17: Pooling Layers
- Day 18: Building Your First CNN
- Day 19: LeNet-5 Architecture
- Day 20: Transfer Learning
- Day 21: Practical Project (VGG/ResNet)

**Projects:** Image classification with CNNs, transfer learning

### Week 4: Deep Learning for Text (Days 22-28)

**Theme:** Recurrent Neural Networks

**Topics:**
- Day 22: Sequential Data
- Day 23: RNNs
- Day 24: Vanishing/Exploding Gradients
- Day 25: LSTMs
- Day 26: GRUs
- Day 27: Bidirectional LSTMs
- Day 28: Sentiment Analysis Project

**Projects:** Sentiment analysis with LSTMs

### Week 5: The Bridge to Transformers (Days 29-35)

**Theme:** Attention Mechanisms

**Topics:**
- Day 29: Word Embeddings (Word2Vec)
- Day 30: GloVe and fastText
- Day 31: Encoder-Decoder Architecture
- Day 32: Seq2Seq Limitations
- Day 33: Attention Mechanism
- Day 34: Visualizing Attention
- Day 35: Seq2Seq Project

**Projects:** Machine translation with attention

### Week 6: The Transformer Architecture (Days 36-42)

**Theme:** Transformers

**Topics:**
- Day 36: Introduction to Transformers
- Day 37: Self-Attention
- Day 38: Multi-Head Attention
- Day 39: Transformer Encoder
- Day 40: Transformer Decoder
- Day 41: Positional Encodings
- Day 42: Complete Transformer Review

**Projects:** Building a transformer from scratch

### Week 7: The Models That Changed the World (Days 43-50)

**Theme:** Modern LLMs

**Topics:**
- Day 43: BERT Architecture
- Day 44: Masked Language Modeling
- Day 45: BERT Fine-tuning
- Day 46: GPT Architecture
- Day 47: Causal Language Modeling
- Day 48: Large Language Models (GPT-3)
- Day 49: BERT vs. GPT vs. T5
- Day 50: Final Project

**Projects:** Fine-tuning BERT/GPT for specific tasks

## Assessment

- **Daily Exercises:** Practice problems and coding exercises
- **Weekly Projects:** Practical implementation projects
- **Final Project:** Capstone project (Day 50)

## Time Commitment

- **Per Day:** 1-2 hours
- **Weekly Projects:** 3-4 hours
- **Total Course:** 50-70 hours

## Resources

### Required Reading
- Daily articles provided in each day's folder
- Research papers (links provided)

### Recommended Books
- "Deep Learning" by Ian Goodfellow
- "Neural Networks and Deep Learning" by Michael Nielsen
- "Hands-On Machine Learning" by AurÃ©lien GÃ©ron

### Online Resources
- [PyTorch Documentation](https://pytorch.org/docs/)
- [Papers With Code](https://paperswithcode.com/)

## Course Policies

### Pacing
- Self-paced learning
- Recommended: one day per day (1-2 hours)
- **Completion Deadline:** December 31st, 2025
- Plan your schedule to finish by the deadline
- If you start later, you can complete multiple days per day or extend your daily time commitment

### Support
- Check daily README files for guidance
- Review FAQ for common questions
- GitHub issues for bug reports

## Certification

While this course doesn't provide formal certification, completing all 50 days demonstrates:
- Strong understanding of deep learning fundamentals
- Ability to implement various architectures
- Practical experience with real-world projects

## Prerequisites Checklist

Before starting, ensure you have:

- [ ] Google Colab account (free, just need a Google account)
- [ ] Basic Python programming knowledge
- [ ] Familiarity with NumPy and Pandas (helpful but not required)
- [ ] Understanding of how to use Google Colab notebooks
- [ ] Knowledge of how to enable GPU runtime in Google Colab (we'll guide you)

**Note:** No local installation required! All work is done in Google Colab, which comes with Python, PyTorch, and all necessary libraries pre-installed.

---

## ðŸŽ¯ Remember: December 31st, 2025

**The course will finish on December 31st, 2025. Let's finish this year's resolution.**

Start today, spend 1-2 hours daily, and you'll complete your 2025 resolution. No more abandoned courses. This year, let's actually do it.

**Ready to start?** Begin with [Day 1](../daily/day%201/) today!

